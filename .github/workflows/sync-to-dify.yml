name: Sync Changed Articles to Dify

on:
  push:
    branches: 
      - main
    paths:
      - 'articles/**.md'
      - 'articles/**.mdx'
  workflow_dispatch:  # ÊâãÂãïÂÆüË°åÁî®Ôºà„Éá„Éê„ÉÉ„Ç∞„Å´‰æøÂà©Ôºâ

jobs:
  sync-changed:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 2
    
    - name: Get changed files
      id: changed-files
      run: |
        # Â§âÊõ¥„Åï„Çå„Åü„Éï„Ç°„Ç§„É´„ÇíÂèñÂæó
        CHANGED=$(git diff --name-only HEAD^ HEAD | grep '^articles/.*\.mdx\?$' || echo "")
        echo "files=$CHANGED" >> $GITHUB_OUTPUT
        
        # „Éá„Éê„ÉÉ„Ç∞Âá∫Âäõ
        echo "Changed files: $CHANGED"
    
    - name: Setup Python
      if: steps.changed-files.outputs.files != ''
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      if: steps.changed-files.outputs.files != ''
      run: pip install requests
    
    - name: Sync changed articles
      if: steps.changed-files.outputs.files != ''
      env:
        DIFY_API_KEY: ${{ secrets.DIFY_API_KEY }}
        DIFY_API_URL: ${{ secrets.DIFY_API_URL }}
        DIFY_DATASET_ID: ${{ secrets.DIFY_DATASET_ID }}
        CHANGED_FILES: ${{ steps.changed-files.outputs.files }}
      run: |
        echo "Starting sync..."
        python - << 'EOF'
        import os
        import json
        import requests
        import time
        
        def extract_metadata(content):
            """„É°„Çø„Éá„Éº„Çø„ÇíÊäΩÂá∫"""
            metadata = {}
            if content.startswith('---'):
                try:
                    end = content.index('---', 3)
                    frontmatter = content[3:end].strip()
                    for line in frontmatter.split('\n'):
                        if ':' in line:
                            key, value = line.split(':', 1)
                            metadata[key.strip()] = value.strip().strip('"\'')
                except:
                    pass
            return metadata
        
        def get_existing_doc_id(doc_name, headers):
            """Êó¢Â≠ò„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆID„ÇíÂèñÂæó"""
            url = f"{api_url}/datasets/{dataset_id}/documents"
            response = requests.get(url, headers=headers, params={"page": 1, "limit": 100})
            if response.status_code == 200:
                for doc in response.json().get('data', []):
                    if doc['name'] == doc_name:
                        return doc['id']
            return None
        
        # Ë®≠ÂÆö
        api_key = os.environ['DIFY_API_KEY']
        api_url = os.environ['DIFY_API_URL']
        dataset_id = os.environ['DIFY_DATASET_ID']
        changed_files = os.environ.get('CHANGED_FILES', '').split()
        
        if not changed_files:
            print("‚ÑπÔ∏è No changed files")
            exit(0)
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        print(f"üöÄ Syncing {len(changed_files)} changed articles")
        
        success = 0
        failed = 0
        
        for filepath in changed_files:
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                doc_name = os.path.basename(filepath)
                metadata = extract_metadata(content)
                
                payload = {
                    "name": doc_name,
                    "text": content,
                    "indexing_technique": "high_quality",
                    "process_rule": {"mode": "automatic"},
                    "metadata": {
                        "source": "github",
                        "path": filepath,
                        "title": metadata.get('title', ''),
                        "commit": os.environ.get('GITHUB_SHA', '')[:7],
                        "sync_time": time.strftime("%Y-%m-%d %H:%M:%S UTC", time.gmtime())
                    }
                }
                
                # Êó¢Â≠ò„Éâ„Ç≠„É•„É°„É≥„Éà„Çí„ÉÅ„Çß„ÉÉ„ÇØ
                doc_id = get_existing_doc_id(doc_name, headers)
                
                if doc_id:
                    url = f"{api_url}/datasets/{dataset_id}/documents/{doc_id}/update_by_text"
                    action = "Updated"
                else:
                    url = f"{api_url}/datasets/{dataset_id}/document/create_by_text"
                    action = "Created"
                
                response = requests.post(url, headers=headers, json=payload)
                
                if response.status_code in [200, 201]:
                    print(f"‚úÖ {action}: {filepath}")
                    if metadata.get('title'):
                        print(f"   üìù {metadata['title']}")
                    success += 1
                else:
                    print(f"‚ùå Failed: {filepath} - {response.status_code}")
                    failed += 1
                    
            except Exception as e:
                print(f"‚ùå Error: {filepath} - {str(e)}")
                failed += 1
        
        print(f"\nüìä Summary: {success} success, {failed} failed")
        
        # GitHub Actions „Çµ„Éû„É™„Éº
        summary_file = os.environ.get('GITHUB_STEP_SUMMARY')
        if summary_file:
            with open(summary_file, 'w') as f:
                f.write(f"# üìö Dify Sync Results\n\n")
                f.write(f"- ‚úÖ Success: {success}\n")
                f.write(f"- ‚ùå Failed: {failed}\n")
                f.write(f"- üìÅ Total: {len(changed_files)}\n")
        
        if failed > 0:
            exit(1)
        EOF
