---
title: "【Amazon Bedrock】Bedrock Agents × Strands Agents × AgentCoreの機能を整理してみた"
emoji: "📘"
type: "tech"
topics:
  - "aws"
  - "aiagent"
  - "bedrock"
  - "amazonbedrock"
  - "agentcore"
published: true
published_at: "2025-08-24 15:00"
---
# はじめに
今回、AWSパートナー向けのセミナーである、`Agent on AWS Dive Deep 〜1 Day Solution Dive Deep シリーズ〜`を受講したので、その内容をまとめていきたいと思います。
内容は`Amazon Bedrockを使用したAI エージェント`についてです。
何回か`Amazon Bedrock AgentCore`や`Strands Agents`を使用したハンズオンは行ったことがありますが、復習を兼ねて基礎を学べたのでとても有益な時間でした。

# AI エージェントの基礎

### AI エージェントとは︖
`環境と対話`し、データを収集し、そのデータを使⽤して`⾃⼰決定タスクを実⾏`して、事前に`決められた⽬標を達成`するためのソフトウェアプログラムです。
https://aws.amazon.com/jp/what-is/ai-agents/

![](/images/71201ab711954e/image-1.png)

### AI エージェントを構成する要素

**1. Perceive（認知）**
単なるデータ入力を超え、センサー、データベース、デジタルインターフェースなど、多様なソースから能動的にデータを収集・処理・統合します。これにより、より広範な状況理解が可能になります。

**2. Reason（推論）**
収集した情報に基づき、タスクを深く理解し、効果的な解決策を生成します。この段階では、LLMが中心的な役割を果たし、さまざまな専門モデルを連携させるオーケストレーターとして機能します。

**3. Act（行動）**
APIを介して外部ツールやソフトウェアと統合することで、エージェントAIは策定した計画に基づいてタスクを迅速に実行できます。

Reason + Act = ReActと呼ばれたりもします。
https://note.com/npaka/n/n99153644e550

![](/images/71201ab711954e/image-2.png)

:::message
**Chain-of-Thought（CoT：思考の連鎖）**
中間的な推論ステップを⽣成させることで、LLMのReasoning能⼒を向上させるプロンプトテクニックです。

通常のプロンプティングでは単一の質問に対して直接的な回答を求めるのに対し、Chain-of-Thoughtプロンプティングでは複雑な問題を分解し、一つ一つのステップを順を追って進めることに重点を置きます。

Chain-of-Thoughtは複雑な問題を小さなステップに分解し、各ステップごとに論理的に進めることが特徴です。これにより、対話型AIが問題をより深く理解し、正確な回答を導き出すことが可能になります。

また、各ステップが論理的に連鎖し、一貫性のある回答が得られます。これにより、回答の整合性が高まり、利用者にとって信頼性の高い情報提供が実現します。

https://ai-market.jp/howto/chain-of-thought/
:::

### Agentic AI への進化
LLM の発展により推論能⼒が⼤幅に向上したことで、アシスタントとしての役割からより少ない⼈⼿で完全⾃動化システムとしての役割も果たせるようになってきています。

![](/images/71201ab711954e/image-3.png)

### AWSのAIスタック
![](/images/71201ab711954e/image-5.png)
![](/images/71201ab711954e/image-4.png)

# Amazon Bedrock Agents
エージェント機能をフルマネージドで提供。
API呼び出しやRAG（Retrieval Augmented Generation）から情報を引き出し、取得した情報を用いてユーザーからの指示やタスクに返答することができます。
![](/images/71201ab711954e/image-6.png)

- ユーザーのクエリをタスクを分割し統合しながら実⾏
- 社内のデータにセキュアにアクセス (検索拡張⽣成; RAG)
- Chain-of-Thought と ReAct の⼿法に基づくプロンプトをトレース・カスタマイズ
- レスポンスのストリーミング出⼒

### メリット
Amazon Bedrock Agentsはサーバレスかつフルマネージドで提供され、追加料金なしにAgentを使用することができます。またAgentに関しても様々なモデルを利用することができます。
またAgentはノーコードで簡単に作成でき、Lambda関数を利用してアクションを作りこむことで色々な用途に活用することができます。

https://aws.amazon.com/jp/bedrock/agents/
https://pages.awscloud.com/rs/112-TZM-766/images/AWS-Black-Belt_2024_Amazon-Bedrock-Agents_0930_v1.pdf
https://business.ntt-east.co.jp/content/cloudsolution/column-578.html#section-5

### Amazon Bedrock Agents の仕組みの全体像
![](/images/71201ab711954e/image-7.png)
![](/images/71201ab711954e/image-8.png)

**1. Action Group**
外部システムと連携するための「スキルセット」です。
エージェントが外部APIやAWSサービスを呼び出すときに使います。
Agentを作るときに「Action Group」を登録すると、エージェントはそのAPI仕様を理解し、必要な時に呼び出せるようになります。
(OpenAPI仕様やLambdaインターフェースで定義可能)

**2. Knowledge Bases**
RAG (Retrieval-Augmented Generation) 用のデータベースです。

**3. Code Interpreter**
数値計算やデータ処理をエージェントに実行させる仕組みです。
「AIがコードを書いて、その場で実行して結果を返す」イメージ。

### 実装例
**⼈事部エージェントの場合**
![](/images/71201ab711954e/image-9.png)
**処理フロー：**
1. ユーザーが「今年の有給はまだ残ってる？」と質問
2. LLM（大規模言語モデル）が質問内容を解釈
3. 休暇取得Action GroupのAPIを呼び出し（employee_id = X で特定）
4. AWS Lambdaが社内システムと連携して休暇データを取得
5. 結果を整形して「6日残っています」とユーザーに回答

**主要コンポーネント：**
**■休暇取得 Action Group**: 特別休暇日数取得、無給給与日数取得、特別休暇予約、有給予約の機能を提供
**■人事 Knowledge Base**: 就労規則検索機能を提供（Amazon OpenSearch Serverlessで実装）
**■バックエンド**: AWS Lambda経由で社内システムのデータベースと連携
**■ドキュメント管理**: Amazon S3で就労規則ドキュメントを保管

# Amazon Bedrock Agents multi-agent collaboration
### マルチエージェント・コラボレーションとは？
複数の専門エージェントが協力して複雑なタスクを処理する仕組みで、以下のような流れで動作します：

**スーパーバイザーエージェント（Supervisor）**がユーザーの指示を受け取り、タスクを分解し、どのサブエージェント（Collaborator）がどの部分を担当するのか判断します 
**サブエージェント**はそれぞれ特定の領域の専門性を持ち、並行してタスクを処理し、結果をスーパーバイザーに返します 
**スーパーバイザー**は最終的にそれらを統合して、ユーザーに対して統一された回答を返します

https://docs.aws.amazon.com/ja_jp/bedrock/latest/userguide/agents-multi-agent-collaboration.html

![](/images/71201ab711954e/image-10.png)

### ルーティングの仕組み
Supervisor agent のために各 collaborator agent の説明を記述
→ 利⽤時は supervisor agent がユーザーのクエリから適切な振り分けを判断

![](/images/71201ab711954e/image-11.png)


**Supervisor agent での連携設定**

| 設定 | 最終的な返答 | 担当ルーティングの仕組み |
| ---- | ---- | ---- |
| **SUPERVISOR** | Supervisor agent | 通常のオーケストレーションのステップとして実施 |
| **SUPERVISOR_ROUTER** | Collaborator agent | ルーティングに特化したステップとして実施 (より⾼速) |

![](/images/71201ab711954e/image-12.png)

### 複雑な処理の⾃動化
![](/images/71201ab711954e/image-13.png)

# Strands Agents
`数⾏のコード`でエージェントを構築できる`オープンソース SDK`
https://aws.amazon.com/jp/blogs/news/introducing-strands-agents-an-open-source-ai-agents-sdk/
https://strandsagents.com/latest/

**軟性、スピード、シンプルさを重視**
![](/images/71201ab711954e/image-14.png)

- **エージェント**: エージェントの中核となる部分です。ユーザーからの指示を受け取り、LLMと連携して「思考」し、必要に応じてツールを呼び出し、最終的な回答を生成する、まさに司令塔の役割を果たします。
- **モデル（LLM）**: Strands Agentsは非常に柔軟なモデルサポートを提供しており、Amazon Bedrock、Anthropic、Ollama、Metaなどのモデルプロバイダー、およびLiteLLMを介したその他のプロバイダーを含む、推論およびツール使用能力を持つ任意のモデルをサポートしています。
- **ツール**: エージェントが利用できるツールは多岐にわたります。 公開されている数千のModel Context Protocol (MCP) サーバーを利用できるほか、ファイル操作、APIリクエスト実行、AWS APIとの連携など、20以上の組み込み済みツール例も提供されています。 また、任意のPython関数をツールとして利用することも可能です。
- **プロンプト**: ユーザーの要望などを自然言語で与え、エージェントが各ツールを呼び出しながらタスクを遂行。エージェントに実行させたいタスクを自然言語で定義する「ユーザープロンプト」と、エージェントの一般的な指示や望ましい振る舞いを定義する「システムプロンプト」の2種類があります。

### サンプルコード（幅広いツールのセレクション）
**Strands Agents の Hello World**
```py
from strands import Agent
from strands_tools import calculator
agent = Agent(tools=[calculator])
response = agent(”What is 80 / 4?")
```

**Amazon Bedrock との連携**
```py
from strands import Agent
from strands.models import BedrockModel
bedrock_model1 = BedrockModel(
model_id= "us.amazon.nova-premier-v1:0",
params={"max_tokens": 1600, "temperature": 0.7}
)
bedrock_model2 = BedrockModel(
model="us.anthropic.claude-3-7-sonnet-20250219-v1:0”
)
agent = Agent(model=bedrock_model1)
response = agent("Tell me about Bedrock")
```

**LiteLLM と連携し他のLLMも利⽤可能**
```py
from strands import Agent
from strands.models.litellm import LiteLLMModel
litellm_model = LiteLLMModel(
model_id= "azure/gpt-4o-mini",
params={"max_tokens": 1600,
"temperature": 0.7}
)
agent = Agent(model=litellm_model)
response = agent("Tell me about LiteLLM")
```

**すぐ使える構築済みツールリポジトリ**
![](/images/71201ab711954e/image-15.png)

HTTPリクエストの例
```py
from strands import Agent
from strands_tools import http_request
agent = Agent(tools=[http_request])
print(agent("Where is the “ +
“International Space Station?"))
```

**簡単にカスタムツールを作成**
```:py
from strands import Agent, tool
@tool
def weather_forecast(city: str, days: int = 3) -> str:
"""Get weather forecast for a city.
Args:
city: The name of the city
days: Number of days for the forecast
"""
return f"Weather forecast for {city} for the next {days} days..."
agent = Agent(tools=[weather_forecast])
print(agent("What's the weather in Seattle tmw?"))
```

**MCP のネイティブサポート**
```py
from mcp import stdio_client, StdioServerParameters
from strands import Agent
from strands.tools.mcp import MCPClient
stdio_mcp_client = MCPClient(lambda: stdio_client(
StdioServerParameters(command="uvx",
args=["awslabs.aws-documentation-mcp-server@latest"]))
)
with stdio_mcp_client:
tools = stdio_mcp_client.list_tools_sync()
agent = Agent(tools=tools)
agent("What does Bedrock InvokeInlineAgent do?")
```

### オブザーバビリティと評価（⾼い柔軟性）
Strands Agents はネイティブにメトリクスと OTEL (OpenTelemetry) トレースを提供
![](/images/71201ab711954e/image-16.png)

# Amazon Bedrock AgentCore（プレビュー）
AgentCore は、あらゆるフレームワークやモデル上で動作する AI エージェントを、安全性・信頼性・ガバナンスを担保しながら、PoCから本番環境へスケール展開するためのサービスです。
https://aws.amazon.com/jp/blogs/news/introducing-amazon-bedrock-agentcore-securely-deploy-and-operate-ai-agents-at-any-scale/

![](/images/71201ab711954e/image-17.png)

`あらゆるフレームワークとモデル`を利⽤して構築した、⾼度な能⼒を持つエージェントを`安全かつ⼤規模にデプロイ`して運⽤。
![](/images/71201ab711954e/image-18.png)

### ⾼度なエージェントを安全かつ⼤規模に実⾏するための基盤サービス
![](/images/71201ab711954e/image-19.png)

### エージェント⽤の安全でスケーラブルなランタイム
- AgentCore Runtime
- AgentCore Identity
![](/images/71201ab711954e/image-20.png)

### 効果的なエージェントを構築するために必要不可⽋なツールと機能
- AgentCore Gateway
- AgentCore Memory
- AgentCore Browser
- AgentCore Code Interpreter
![](/images/71201ab711954e/image-21.png)

### 信頼できるエージェント運⽤のための可視性
- AgentCore Observability
![](/images/71201ab711954e/image-22.png)


### AgentCore Runtime
>セッション分離を備え、サンドボックス化された低レイテンシーのサーバーレス環境を提供し、人気のオープンソースフレームワーク、ツール、モデルを含むあらゆるエージェントフレームワークをサポートし、マルチモーダルワークロードと長時間実行エージェントを処理します。

**これまでの課題**
**「作成したエージェントを本番環境で利⽤するには︖」**
- エージェント実⾏に Lambda（15 分制限）や EC2 を使⽤、
インフラ管理が複雑
- ⻑時間実⾏、⼤容量ペイロード、セッション分離が必要
- フレームワーク毎に異なる実⾏環境、デプロイの複雑さ

![](/images/71201ab711954e/image-23.png)
![](/images/71201ab711954e/image-24.png)

**5分で AI エージェントをデプロイ・ホスティングする – Amazon Bedrock AgentCore Runtime**
https://aws.amazon.com/jp/blogs/startup/5min-ai-agent-hosting/

**Bedrock AgentCore SDK を使った実装例**
![](/images/71201ab711954e/image-25.png)

### AgentCore Identity
**これまでの課題**
**「AI エージェントが⼈間の代理で⾏動する際の認証・認可の複雑さ」**
- エージェントは外部リソースにアクセスするため、ユーザーの認証認可に加えてエージェントの認証認可が必要
![](/images/71201ab711954e/image-26.png)

**AI エージェントを発端とするアクセスの認証認可を既存のシステムで⼀元管理**
![](/images/71201ab711954e/image-27.png)
![](/images/71201ab711954e/image-28.png)

**AgentCore Identity**ではInbound AuthとOutbound Authの2種類の認証が存在します。
**Inbound Auth**
ユーザーやサービスがエージェントを呼び出す際には、IAM（SigV4）、OAuth 2.0 / OpenID Connect、JWTなどで検証されます。
**Outbound Auth**
エージェントがリソースへアクセスする際は、トークンや API キーを安全に取得し使用します（3-legged / 2-legged OAuth や API キー対応）。
![](/images/71201ab711954e/image-30.png)

https://aws.amazon.com/jp/blogs/machine-learning/introducing-amazon-bedrock-agentcore-identity-securing-agentic-ai-at-scale/

### AgentCore Gateway
MCP⾮対応の既存サービスを、エージェントからMCPによって呼び出し可能に。

`AgentCore Gateway`は、AIエージェントが外部ツールやサービスへ安全にアクセスするためのゲートウェイ機能です。
企業内のREST APIやデータベース、AWS Lambda、SaaSなどを最小限のコード変更で「エージェント対応ツール」に変換できます。
さらにMCP（Model Context Protocol）やA2A（Agent-to-Agent）といった標準プロトコルに対応し、接続可能な外部機能の範囲を拡大します。
Gatewayではアクセス制御も一元管理でき、認証・認可を通じてセキュアな連携を実現。これにより、エージェントは社内外のリソースと柔軟につながり、最新データを活用した回答や高度なタスク実行が可能になります。
![](/images/71201ab711954e/image-29.png)
![](/images/71201ab711954e/image-31.png)

**AgentCore Gateway セマンティックサーチ**
AgentCore Gateway セマンティックサーチは、エージェントが多数のツールから文脈に沿った最適なツールを意味的に探索できる仕組みです。
キーワードベースではなく意味的関連性での選定が可能なため、無関係なツール選択による誤答やレイテンシーを軽減できます。
ツール数が増える大規模環境でも、効率的にツールを検索・利用でき、開発の複雑さを抑制します。
![](/images/71201ab711954e/image-32.png)

### AgentCore Memory
セッションや”⻑期記憶”を保存し、コンテキスト維持の実現を容易に。

`AgentCore Memory` は、エージェントに文脈を覚えさせ、継続的でパーソナライズされた対話を可能にする記憶基盤サービスです。
開発者のメモリ構築の手間を軽減しつつ、エージェントの応答精度や利便性を向上させます。
大きく分けて2種類の記憶を管理できます。
![](/images/71201ab711954e/image-33.png)
![](/images/71201ab711954e/image-34.png)

https://dev.classmethod.jp/articles/amazon-bedrock-agentcore-memory-sample-agent/
https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory.html?utm_source=chatgpt.com

![](/images/71201ab711954e/image-35.png)

### AgentCore Browser
`AgentCore Browser` はエージェントがウェブサイトとインタラクションできる安全なクラウドベースのブラウザ環境を提供するツールです。AgentCore内のコンテナ化されたインフラ上で動作し、エージェントが人間と同様にウェブを参照し、フォーム入力やクリック、動的コンテンツの解析などの操作が可能になります。

AIが直接ウェブページを読み取り、操作、情報取得できるようになります。具体的には以下のようなことが可能です。
- **ウェブページの閲覧、操作**
■HTMLやDOMを解析してページの内容を理解できる
■ページ内のテキストやリンク、ボタンなどの情報を取得可能
■ページ内のリンクをクリック
■フォーム入力や送信
■ページ内のスクロール、タブ切り替えなど

- **外部ツールとの連携**
■AgentCore GatewayやMemoryと連携して、AIの判断に基づきウェブ操作を実行
■必要な情報だけを抽出して社内システムやデータベースに反映

![](/images/71201ab711954e/image-36.png)
![](/images/71201ab711954e/image-37.png)

https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/browser-tool.html

### AgentCore Code Interpreter
`AgentCore Code Interpreter`は、AIエージェントにコードを解析・実行・生成する能力を付与するモジュールです。
簡単に言うと、AIが「プログラムを書いたり動かしたりして結果を得る」ことができるようになります。
■複数のプログラミング言語に対応（Python, JavaScript, TypeScriptなど）
■完全なサンドボックス環境かパブリックネットワーク環境かを選択可能
■デフォルト15分、最長8時間までの長時間実行をサポート
■大容量ファイルのインラインアップロードやS3経由でアップロードサポートなど
![](/images/71201ab711954e/image-38.png)
![](/images/71201ab711954e/image-39.png)

### AgentCore Observability
AgentCore Observabilityは、AIエージェントの動作や処理状況を監視・可視化・分析するためのモジュールです。
AIの挙動を把握し、問題の特定や改善に役立てることができます。

![](/images/71201ab711954e/image-40.png)
![](/images/71201ab711954e/image-41.png)
https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/observability.html

### ⼤規模なエージェント展開のための AgentCore 機能
![](/images/71201ab711954e/image-42.png)
![](/images/71201ab711954e/image-43.png)

# おわりに
Amazon Bedrockを活用したAIエージェントの基礎から、AgentCoreを利用した高度な運用までを整理しました。
Bedrock AgentsやStrands Agentsを活用することで、複雑な業務やマルチエージェントの協調タスクまで自動化できる点やAgentCoreの各モジュール—Gateway、Memory、Browser、Code Interpreter、Observability—を組み合わせることで、エージェントは安全かつスケーラブルに、長時間・大規模の処理も実行可能になります。
AI関連のサービスは今後も変化していくと思われるので、積極的にキャッチアップしていこうと思います。